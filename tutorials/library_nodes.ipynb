{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library Nodes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`LibraryNode`s facilitate the abstraction of common operations, enabling easy reuse in different SDFGs and Data-Centric progrmas. This tutorial covers creating `LibraryNode`s with different implelementations (called *expansions* or `ExpandTransformation`s), and how to use them in SDFGs or Data-Centric programs."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this tutorial, we use as an example the SDDMM (sampled dense-dense matrix multiplication) operation:\n",
    "$$\\bm{D} = \\bm{A} \\odot \\left(\\bm{B} \\times \\bm{C}\\right)$$\n",
    "$\\bm{A}$ is a sparse matrix, while $\\bm{B}$ and $\\bm{C}$ are dense matrices. The ouput $\\bm{D}$ is the Hadamard (element-wise) product of $\\bm{A}$ and the matrix product of $\\bm{B}$ and $\\bm{C}$, and has the same sparsity pattern as $\\bm{A}$. Effectively, $\\bm{A}$ *samples* (or filters) the dense product $\\bm{B} \\times \\bm{C}$. Assuming $\\bm{A}$ is in CSR format, the SDDMM algorithm is as follows:\n",
    "\n",
    "```python\n",
    "# A (D) has shape (M, N) with nnz non-zero values\n",
    "# A_data (D_data) is the non-zero values of A (D)\n",
    "# A_indices (D_indices) is the column indices of A (D)\n",
    "# A_indptr (D_indptr) is the row pointers of A (D)\n",
    "# B has shape (M, K)\n",
    "# C has shape (K, N)\n",
    "D_data = np.zeros_like(A_data)\n",
    "D_indices = np.copy(A_indices)\n",
    "D_indptr = np.copy(A_indptr)\n",
    "for i in range(M):\n",
    "    for j in range(A_indptr[i], A_indptr[i + 1]):\n",
    "        for k in range(K):\n",
    "            D_data[j] += B[i, k] * C[k, A_indices[j]]\n",
    "        D_data[j] *= A_data[j]\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by creating a LibraryNode that represents the SDDMM operation. We create a class that inherits from `dace.sdfg.nodes.LibraryNode`, and we decorate it with `@dace.library.node`. The class must include an `implementations` dictionary, and an `defaul_implementation` string, which we will discuss later. The `LibraryNode`'s initialization method must call the initialization method of the super-class and pass the node's name, location, inputs, and outputs. The inputs and the outputs are the node's connector names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dace\n",
    "\n",
    "from dace import library\n",
    "from dace.sdfg import nodes\n",
    "from dace.transformation import ExpandTransformation\n",
    "from typing import Dict\n",
    "\n",
    "\n",
    "@library.node\n",
    "class MySDDMM(nodes.LibraryNode):\n",
    "\n",
    "    # We will fill those later\n",
    "    implementations: Dict[str, ExpandTransformation] = {}\n",
    "    default_implementation: str = None\n",
    "\n",
    "    def __init__(self, name, location=None):\n",
    "        super().__init__(name,\n",
    "                         location=location,\n",
    "                         inputs={'_a_data', '_a_indices', '_a_indptr', '_b', '_c'},\n",
    "                         outputs={'_d_data', '_d_indices', '_d_indptr'})\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `LibraryNode` can have different implemenetations (expansions), generic or specialized for specific architectures. These implementations can use the SDFG API but they can also be written as Data-Centric programs. We start by creating a *pure* expansion, which is an implementation that does not use any components, e.g., libraries, external to DaCe. We write this expansion as a Data-Centric Python program:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@library.expansion\n",
    "class MySDDMMPureExpansion(ExpandTransformation):\n",
    "\n",
    "    environments = []\n",
    "\n",
    "    @staticmethod\n",
    "    def expansion(node, state, sdfg):\n",
    "\n",
    "        # Find shapes and datatypes of inputs and outputs\n",
    "\n",
    "        # A matrix\n",
    "        a_indptr_name = list(state.in_edges_by_connector(node, '_a_indptr'))[0].data.data\n",
    "        a_indptr_arr = sdfg.arrays[a_indptr_name]\n",
    "        a_data_name = list(state.in_edges_by_connector(node, '_a_data'))[0].data.data\n",
    "        a_data_arr = sdfg.arrays[a_data_name]\n",
    "        a_rowsp1 = a_indptr_arr.shape[0]\n",
    "        a_nnz = a_data_arr.shape[0]\n",
    "        a_dtype = a_data_arr.dtype\n",
    "\n",
    "        # B matrix\n",
    "        b_name = list(state.in_edges_by_connector(node, '_b'))[0].data.data\n",
    "        b_arr = sdfg.arrays[b_name]\n",
    "        b_rows = b_arr.shape[0]\n",
    "        b_cols = b_arr.shape[1]\n",
    "        b_dtype = b_arr.dtype\n",
    "\n",
    "        # C matrix\n",
    "        c_name = list(state.in_edges_by_connector(node, '_c'))[0].data.data\n",
    "        c_arr = sdfg.arrays[c_name]\n",
    "        c_rows = c_arr.shape[0]\n",
    "        c_cols = c_arr.shape[1]\n",
    "        c_dtype = c_arr.dtype\n",
    "\n",
    "        # D matrix\n",
    "        # We assume that it has the same shape and datatype as A\n",
    "\n",
    "        @dace.program\n",
    "        def sddmm_pure(_a_data: a_dtype[a_nnz], _a_indices: dace.int32[a_nnz], _a_indptr: dace.int32[a_rowsp1],\n",
    "                       _b: b_dtype[b_rows, b_cols], _c: c_dtype[c_rows, c_cols],\n",
    "                       _d_data: a_dtype[a_nnz], _d_indices: dace.int32[a_nnz], _d_indptr: dace.int32[a_rowsp1]):\n",
    "\n",
    "            _d_data[:] = 0\n",
    "            _d_indices[:] = _a_indices\n",
    "            _d_indptr[:] = _a_indptr\n",
    "\n",
    "            for i in dace.map[0:a_rowsp1 - 1]:\n",
    "                for j in dace.map[_a_indptr[i]:_a_indptr[i + 1]]:\n",
    "                    for k in dace.map[0:b_cols]:\n",
    "                        _d_data[j] += _b[i, k] * _c[k, _a_indices[j]]\n",
    "                    _d_data[j] *= _a_data[j]\n",
    "\n",
    "        return sddmm_pure.to_sdfg()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To enable the above expansion, we add it to the `implementations` dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@library.node\n",
    "class MySDDMM(nodes.LibraryNode):\n",
    "\n",
    "    implementations: Dict[str, ExpandTransformation] = {'pure': MySDDMMPureExpansion}\n",
    "    default_implementation: str = None\n",
    "\n",
    "    def __init__(self, name, location=None):\n",
    "        super().__init__(name,\n",
    "                         location=location,\n",
    "                         inputs={'_a_data', '_a_indices', '_a_indptr', '_b', '_c'},\n",
    "                         outputs={'_d_data', '_d_indices', '_d_indptr'})\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that there is at least one expansion for the `LibraryNode`, we can use it in an SDFG like any other `CodeNode` or `Tasklet`. However, it is also possible to automate its use in Data-Centric Python programs. We us as an example the inference formula for a single-layer of the Vanilla Attention (VA) Graph Neural Network (GNN):\n",
    "$$\\bm{H}^\\prime = \\sigma\\left(\\bm{A} \\odot \\left(\\bm{H} \\times \\bm{H}^T\\right) \\times \\bm{H} \\times \\bm{W}\\right)$$\n",
    "We implement the above formula as a Data-Centric Python program:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# A is N x N, H is N x K0, W is K0 x K1, H' is N x K1\n",
    "N, K0, K1, NNZ = (dace.symbol(s) for s in ('N', 'K0', 'K1', 'NNZ'))\n",
    "\n",
    "@dace.program\n",
    "def va_inference_layer(A_data: dace.float32[NNZ], A_indices: dace.int32[NNZ], A_indptr: dace.int32[N + 1],\n",
    "                       H: dace.float32[N, K0],\n",
    "                       W: dace.float32[K0, K1],\n",
    "                       H_prime: dace.float32[N, K1]):\n",
    "    \n",
    "    # S = A \\odot (H \\times H^T)\n",
    "    # S_data = np.empty_like(A_data)\n",
    "    # S_indices = np.empty_like(A_indices)\n",
    "    # S_indptr = np.empty_like(A_indptr)\n",
    "    # dace.sddmm_op(A_data, A_indices, A_indptr, W, H, np.transpose(H), S_data, S_indices, S_indptr)\n",
    "    S_data, S_indices, S_indptr = dace.sddmm_op(A_data, A_indices, A_indptr, H, np.transpose(H))\n",
    "\n",
    "    H_prime[:] = np.maximum(0, dace.csrmm_op(S_data, S_indices, S_indptr, H) @ W)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to convert the above program to SDFG, we need to define `SDDMM_op` and `CSRMM_op`. For the latter, there is\n",
    "already a suitable `LibraryNode` in DaCe that we can use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dace.frontend.common import op_repository \n",
    "\n",
    "\n",
    "@op_repository.replaces('dace.sddmm_op')\n",
    "def sddmm_libnode(pv: 'ProgramVisitor',\n",
    "                  sdfg: dace.SDFG,\n",
    "                  state: dace.SDFGState,\n",
    "                  A_data: str,\n",
    "                  A_indices: str,\n",
    "                  A_indptr: str,\n",
    "                  B: str,\n",
    "                  C: str):\n",
    "    # Input access nodes\n",
    "    A_data_acc, A_indices_acc, A_indptr_acc, B_acc, C_acc = (\n",
    "        state.add_access(n) for n in (A_data, A_indices, A_indptr, B, C))\n",
    "    # Output D\n",
    "    A_data_arr = sdfg.arrays[A_data]\n",
    "    A_indices_arr = sdfg.arrays[A_indices]\n",
    "    A_indptr_arr = sdfg.arrays[A_indptr]\n",
    "    D_data, D_data_arr = sdfg.add_temp_transient_like(A_data_arr)\n",
    "    D_indices, D_indices_arr = sdfg.add_temp_transient_like(A_indices_arr)\n",
    "    D_indptr, D_indptr_arr = sdfg.add_temp_transient_like(A_indptr_arr)\n",
    "    D_data_acc, D_indices_acc, D_indptr_acc = (state.add_access(n) for n in (D_data, D_indices, D_indptr))\n",
    "\n",
    "    libnode = MySDDMM('sddmm')\n",
    "    state.add_node(libnode)\n",
    "\n",
    "    # Connect nodes\n",
    "    state.add_edge(A_indptr_acc, None, libnode, '_a_indptr', dace.Memlet(A_indptr))\n",
    "    state.add_edge(A_indices_acc, None, libnode, '_a_indices', dace.Memlet(A_indices))\n",
    "    state.add_edge(A_data_acc, None, libnode, '_a_data', dace.Memlet(A_data))\n",
    "    state.add_edge(B_acc, None, libnode, '_b', dace.Memlet(B))\n",
    "    state.add_edge(C_acc, None, libnode, '_c', dace.Memlet(C))\n",
    "    state.add_edge(libnode, '_d_data', D_data_acc, None, dace.Memlet(D_data))\n",
    "    state.add_edge(libnode, '_d_indices', D_indices_acc, None, dace.Memlet(D_indices))\n",
    "    state.add_edge(libnode, '_d_indptr', D_indptr_acc, None, dace.Memlet(D_indptr))\n",
    "\n",
    "    return [D_data, D_indices, D_indptr]\n",
    "\n",
    "\n",
    "@op_repository.replaces('dace.csrmm_op')\n",
    "def csrmm_libnode(pv: 'ProgramVisitor',\n",
    "                  sdfg: dace.SDFG,\n",
    "                  state: dace.SDFGState,\n",
    "                  A_data: str,\n",
    "                  A_indices: str,\n",
    "                  A_indptr: str,\n",
    "                  B: str):\n",
    "    # Input access nodes\n",
    "    A_data_acc, A_indices_acc, A_indptr_acc, B_acc = (state.add_access(n) for n in (A_data, A_indices, A_indptr, B))\n",
    "    # Output C\n",
    "    A_indptr_arr = sdfg.arrays[A_indptr]\n",
    "    rows = A_indptr_arr.shape[0] - 1\n",
    "    cols = sdfg.arrays[B].shape[1]\n",
    "    A_data_arr = sdfg.arrays[A_data]\n",
    "    dtype = A_data_arr.dtype\n",
    "    C, C_arr = sdfg.add_temp_transient([rows, cols], dtype)\n",
    "    C_acc = state.add_write(C)\n",
    "\n",
    "    from dace.libraries.sparse import CSRMM\n",
    "    libnode = CSRMM('csrmm')\n",
    "    state.add_node(libnode)\n",
    "\n",
    "    # Connect nodes\n",
    "    state.add_edge(A_indptr_acc, None, libnode, '_a_rows', dace.Memlet(A_indptr))\n",
    "    state.add_edge(A_indices_acc, None, libnode, '_a_cols', dace.Memlet(A_indices))\n",
    "    state.add_edge(A_data_acc, None, libnode, '_a_vals', dace.Memlet(A_data))\n",
    "    state.add_edge(B_acc, None, libnode, '_b', dace.Memlet(B))\n",
    "    state.add_edge(libnode, '_c', C_acc, None, dace.Memlet(C))\n",
    "\n",
    "    return [C]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One last thing needed to utilize `LibraryNode`s is to register them with a (DaCe) library and set a default implementation. For more information, you can check the `dace.library` submodule. For this tutorial, we will use the existing `sparse` library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dace.library import register_node\n",
    "from dace.libraries import sparse\n",
    "\n",
    "register_node(MySDDMM, sparse)\n",
    "MySDDMM.default_implementation = 'pure'\n",
    "sparse.CSRMM.default_implementation = 'pure'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically expanded library node \"_Transpose_\" with implementation \"pure\".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alziogas/Projects/dace/dace/sdfg/propagation.py:1416: UserWarning: Cannot find appropriate memlet pattern to propagate j through __map_47_b0:__map_47_e1\n",
      "  warnings.warn('Cannot find appropriate memlet pattern to '\n",
      "/home/alziogas/Projects/dace/dace/sdfg/propagation.py:1416: UserWarning: Cannot find appropriate memlet pattern to propagate j through __map_19_b0:__map_19_e1\n",
      "  warnings.warn('Cannot find appropriate memlet pattern to '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically expanded library node \"sddmm\" with implementation \"pure\".\n",
      "Automatically expanded library node \"csrmm\" with implementation \"pure\".\n",
      "Automatically expanded library node \"_MatMult_\" with implementation \"specialize\".\n",
      "Automatically expanded library node \"_MatMult_gemm\" with implementation \"pure\".\n",
      "-- Configuring done\n",
      "-- Generating done\n",
      "-- Build files have been written to: /home/alziogas/Projects/dace/tutorials/.dacecache/va_inference_layer/build\n",
      "\n",
      "[ 25%] Building CXX object CMakeFiles/va_inference_layer.dir/home/alziogas/Projects/dace/tutorials/.dacecache/va_inference_layer/src/cpu/va_inference_layer.cpp.o\n",
      "In file included from /home/alziogas/Projects/dace/dace/codegen/../runtime/include/dace/dace.h:14,\n",
      "                 from /home/alziogas/Projects/dace/tutorials/.dacecache/va_inference_layer/src/cpu/va_inference_layer.cpp:2:\n",
      "/home/alziogas/Projects/dace/dace/codegen/../runtime/include/dace/types.h: In constructor 'dace::half::half(float)':\n",
      "/home/alziogas/Projects/dace/dace/codegen/../runtime/include/dace/types.h:92:28: warning: dereferencing type-punned pointer will break strict-aliasing rules [-Wstrict-aliasing]\n",
      "             uint32_t x = *((uint32_t*)&f);\n",
      "                           ~^~~~~~~~~~~~~~\n",
      "/home/alziogas/Projects/dace/tutorials/.dacecache/va_inference_layer/src/cpu/va_inference_layer.cpp: In function 'void __program_va_inference_layer_internal(va_inference_layer_t*, float*, int*, int*, float*, float*, float*, int, int, int, int)':\n",
      "/home/alziogas/Projects/dace/tutorials/.dacecache/va_inference_layer/src/cpu/va_inference_layer.cpp:273:51: warning: 'new' of type 'float' with extended alignment 64 [-Waligned-new=]\n",
      "         __tmp0 = new float DACE_ALIGN(64)[(K0 * N)];\n",
      "                                                   ^\n",
      "/home/alziogas/Projects/dace/tutorials/.dacecache/va_inference_layer/src/cpu/va_inference_layer.cpp:273:51: note: uses 'void* operator new [](std::size_t)', which does not have an alignment parameter\n",
      "/home/alziogas/Projects/dace/tutorials/.dacecache/va_inference_layer/src/cpu/va_inference_layer.cpp:273:51: note: use '-faligned-new' to enable C++17 over-aligned new support\n",
      "/home/alziogas/Projects/dace/tutorials/.dacecache/va_inference_layer/src/cpu/va_inference_layer.cpp:275:51: warning: 'new' of type 'float' with extended alignment 64 [-Waligned-new=]\n",
      "         __tmp4 = new float DACE_ALIGN(64)[(K0 * N)];\n",
      "                                                   ^\n",
      "/home/alziogas/Projects/dace/tutorials/.dacecache/va_inference_layer/src/cpu/va_inference_layer.cpp:275:51: note: uses 'void* operator new [](std::size_t)', which does not have an alignment parameter\n",
      "/home/alziogas/Projects/dace/tutorials/.dacecache/va_inference_layer/src/cpu/va_inference_layer.cpp:275:51: note: use '-faligned-new' to enable C++17 over-aligned new support\n",
      "/home/alziogas/Projects/dace/tutorials/.dacecache/va_inference_layer/src/cpu/va_inference_layer.cpp:277:51: warning: 'new' of type 'float' with extended alignment 64 [-Waligned-new=]\n",
      "         __tmp5 = new float DACE_ALIGN(64)[(K1 * N)];\n",
      "                                                   ^\n",
      "/home/alziogas/Projects/dace/tutorials/.dacecache/va_inference_layer/src/cpu/va_inference_layer.cpp:277:51: note: uses 'void* operator new [](std::size_t)', which does not have an alignment parameter\n",
      "/home/alziogas/Projects/dace/tutorials/.dacecache/va_inference_layer/src/cpu/va_inference_layer.cpp:277:51: note: use '-faligned-new' to enable C++17 over-aligned new support\n",
      "/home/alziogas/Projects/dace/tutorials/.dacecache/va_inference_layer/src/cpu/va_inference_layer.cpp:279:46: warning: 'new' of type 'float' with extended alignment 64 [-Waligned-new=]\n",
      "         S_data = new float DACE_ALIGN(64)[NNZ];\n",
      "                                              ^\n",
      "/home/alziogas/Projects/dace/tutorials/.dacecache/va_inference_layer/src/cpu/va_inference_layer.cpp:279:46: note: uses 'void* operator new [](std::size_t)', which does not have an alignment parameter\n",
      "/home/alziogas/Projects/dace/tutorials/.dacecache/va_inference_layer/src/cpu/va_inference_layer.cpp:279:46: note: use '-faligned-new' to enable C++17 over-aligned new support\n",
      "/home/alziogas/Projects/dace/tutorials/.dacecache/va_inference_layer/src/cpu/va_inference_layer.cpp:281:47: warning: 'new' of type 'int' with extended alignment 64 [-Waligned-new=]\n",
      "         S_indices = new int DACE_ALIGN(64)[NNZ];\n",
      "                                               ^\n",
      "/home/alziogas/Projects/dace/tutorials/.dacecache/va_inference_layer/src/cpu/va_inference_layer.cpp:281:47: note: uses 'void* operator new [](std::size_t)', which does not have an alignment parameter\n",
      "/home/alziogas/Projects/dace/tutorials/.dacecache/va_inference_layer/src/cpu/va_inference_layer.cpp:281:47: note: use '-faligned-new' to enable C++17 over-aligned new support\n",
      "/home/alziogas/Projects/dace/tutorials/.dacecache/va_inference_layer/src/cpu/va_inference_layer.cpp:283:50: warning: 'new' of type 'int' with extended alignment 64 [-Waligned-new=]\n",
      "         S_indptr = new int DACE_ALIGN(64)[(N + 1)];\n",
      "                                                  ^\n",
      "/home/alziogas/Projects/dace/tutorials/.dacecache/va_inference_layer/src/cpu/va_inference_layer.cpp:283:50: note: uses 'void* operator new [](std::size_t)', which does not have an alignment parameter\n",
      "/home/alziogas/Projects/dace/tutorials/.dacecache/va_inference_layer/src/cpu/va_inference_layer.cpp:283:50: note: use '-faligned-new' to enable C++17 over-aligned new support\n",
      "[ 50%] Linking CXX shared library libva_inference_layer.so\n",
      "[ 50%] Built target va_inference_layer\n",
      "[100%] Built target dacestub_va_inference_layer\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9.3466355e-08"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "A = sparse.random(1000, 1000, density=0.01, dtype=np.float32, format='csr', random_state=rng)\n",
    "A.data[:] = 1\n",
    "H = rng.random((1000, 128), dtype=np.float32)\n",
    "W = rng.random((128, 128), dtype=np.float32)\n",
    "\n",
    "val = np.empty((1000, 128), dtype=np.float32)\n",
    "sdfg = va_inference_layer.to_sdfg()\n",
    "func = sdfg.compile()\n",
    "func(A_data=A.data.copy(), A_indices=A.indices.copy(), A_indptr=A.indptr.copy(), H=H, W=W, H_prime=val, N=1000, K0=128, K1=128, NNZ=A.nnz)\n",
    "\n",
    "ref = np.maximum(0, (A.toarray() * (H @ H.T)) @ H @ W)\n",
    "\n",
    "np.allclose(ref, val)\n",
    "np.linalg.norm(ref - val) / np.linalg.norm(ref)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest part of this tutorial requires an NVIDIA GPU and the CUDA toolkit.\n",
    "\n",
    "When auto-optimizing DaCe programs, DaCe will automatically select faster implementations for `LibraryNode`s, if available. For example, the cuSPARSE library has an SDDMM implementation, which we can utilize in a \"cuSPARSE\" expansion. Please note that the purpose of this tutorial is not to teach CUDA programming or the use of NVIDIA's libraries. The code uses below largely follows NVIDIA's cuSPARSE documentation, which you can consult for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from dace.libraries.blas.blas_helpers import cublas_type_metadata, to_cublas_computetype\n",
    "from dace.libraries.sparse.environments import cuSPARSE\n",
    "\n",
    "@library.expansion\n",
    "class MySDDMMCuSPARSEExpansion(ExpandTransformation):\n",
    "\n",
    "    environments = [cuSPARSE]\n",
    "\n",
    "    @staticmethod\n",
    "    def expansion(node, state, sdfg):\n",
    "\n",
    "        # Find shapes and datatypes of inputs and outputs\n",
    "\n",
    "        # A matrix\n",
    "        a_indptr_name = list(state.in_edges_by_connector(node, '_a_indptr'))[0].data.data\n",
    "        a_indptr_arr = sdfg.arrays[a_indptr_name]\n",
    "        a_indices_name = list(state.in_edges_by_connector(node, '_a_indices'))[0].data.data\n",
    "        a_indices_arr = sdfg.arrays[a_indices_name]\n",
    "        a_data_name = list(state.in_edges_by_connector(node, '_a_data'))[0].data.data\n",
    "        a_data_arr = sdfg.arrays[a_data_name]\n",
    "        a_rowsp1 = a_indptr_arr.shape[0]\n",
    "        a_nnz = a_data_arr.shape[0]\n",
    "        a_dtype = a_data_arr.dtype\n",
    "\n",
    "        # B matrix\n",
    "        b_name = list(state.in_edges_by_connector(node, '_b'))[0].data.data\n",
    "        b_arr = sdfg.arrays[b_name]\n",
    "        b_rows = b_arr.shape[0]\n",
    "        b_cols = b_arr.shape[1]\n",
    "        b_dtype = b_arr.dtype\n",
    "\n",
    "        # C matrix\n",
    "        c_name = list(state.in_edges_by_connector(node, '_c'))[0].data.data\n",
    "        c_arr = sdfg.arrays[c_name]\n",
    "        c_rows = c_arr.shape[0]\n",
    "        c_cols = c_arr.shape[1]\n",
    "        c_dtype = c_arr.dtype\n",
    "\n",
    "        # D matrix\n",
    "        # We assume that it has the same shape and datatype as A\n",
    "        d_indptr_name = list(state.out_edges_by_connector(node, '_d_indptr'))[0].data.data\n",
    "        d_indptr_arr = sdfg.arrays[d_indptr_name]\n",
    "        d_indices_name = list(state.out_edges_by_connector(node, '_d_indices'))[0].data.data\n",
    "        d_indices_arr = sdfg.arrays[d_indices_name]\n",
    "        d_data_name = list(state.out_edges_by_connector(node, '_d_data'))[0].data.data\n",
    "        d_data_arr = sdfg.arrays[d_data_name]\n",
    "\n",
    "        # If buffers are not on the GPU, copy them\n",
    "        needs_copy = any(desc.storage not in (dace.StorageType.GPU_Global, dace.StorageType.CPU_Pinned)\n",
    "                         for desc in (a_data_arr, b_arr, c_arr, d_data_arr))\n",
    "        \n",
    "        dtype = a_data_arr.dtype.base_type\n",
    "        cdtype = cublas_type_metadata(dtype)[1]\n",
    "        compute = f'CUDA_R_{to_cublas_computetype(dtype)}'\n",
    "        handle = '__dace_cusparse_handle'\n",
    "\n",
    "        call_prefix = cuSPARSE.handle_setup_code(node)\n",
    "        call_suffix = ''\n",
    "\n",
    "        # Deal with complex input constants\n",
    "        if isinstance(b_arr, np.complexfloating):\n",
    "            alpha = f'{dtype.ctype}(1, 0)'\n",
    "            beta = f'{dtype.ctype}(0, 0)'\n",
    "        else:\n",
    "            alpha = f'{dtype.ctype}(1)'\n",
    "            beta = f'{dtype.ctype}(0)'\n",
    "\n",
    "        # Set pointer mode to host\n",
    "        call_prefix += f'''cusparseSetPointerMode(__dace_cusparse_handle, CUSPARSE_POINTER_MODE_DEVICE);\n",
    "        {cdtype} alpha = {alpha};\n",
    "        {cdtype} beta = {beta};\n",
    "        '''\n",
    "\n",
    "        arr_prefix = ''\n",
    "        if needs_copy:\n",
    "            arr_prefix = '_conn'\n",
    "\n",
    "        call = f\"\"\"\n",
    "            // Please note that cuSPARSE defines SDDMM as (AxB)oC, while we defined it earier as Ao(BxC),\n",
    "            // where 'o' is the Hadamard product. In other words, in cuSPARSE, C is the sparse matrix that samples\n",
    "            // the dense product of B and C. We will continue using our notation here, but please keep this in mind.\n",
    "\n",
    "            // Copy/set output\n",
    "            cudaMemcpy({arr_prefix}_d_indptr, {arr_prefix}_a_indptr, {a_rowsp1} * sizeof(int32_t), cudaMemcpyDeviceToDevice);\n",
    "            cudaMemcpy({arr_prefix}_d_indices, {arr_prefix}_a_indices, {a_nnz} * sizeof(int32_t), cudaMemcpyDeviceToDevice);\n",
    "            cudaMemcpy({arr_prefix}_d_data, {arr_prefix}_a_data, {a_nnz} * sizeof({dtype.ctype}), cudaMemcpyDeviceToDevice);\n",
    "            \n",
    "            cusparseSpMatDescr_t matA;\n",
    "            cusparseDnMatDescr_t matB, matC;\n",
    "            void*                dBuffer    = NULL;\n",
    "            size_t               bufferSize = 0;\n",
    "\n",
    "            // Create sparse matrix A (D) in CSR format\n",
    "            dace::sparse::CheckCusparseError( cusparseCreateCsr(&matA, {a_rowsp1 - 1}, {b_rows}, {a_nnz},\n",
    "                                                {arr_prefix}_d_indptr, {arr_prefix}_d_indices, {arr_prefix}_d_data,\n",
    "                                                CUSPARSE_INDEX_32I, CUSPARSE_INDEX_32I,\n",
    "                                                CUSPARSE_INDEX_BASE_ZERO, {compute}) );\n",
    "            // Create dense matrix B\n",
    "            dace::sparse::CheckCusparseError( cusparseCreateDnMat(&matB, {b_rows}, {b_cols}, {b_cols}, {arr_prefix}_b,\n",
    "                                                {compute}, CUSPARSE_ORDER_ROW) );\n",
    "            // Create dense matrix C\n",
    "            dace::sparse::CheckCusparseError( cusparseCreateDnMat(&matC, {c_rows}, {c_cols}, {c_cols}, {arr_prefix}_c,\n",
    "                                                {compute}, CUSPARSE_ORDER_ROW) );\n",
    "            // allocate an external buffer if needed\n",
    "            dace::sparse::CheckCusparseError( cusparseSDDMM_bufferSize(\n",
    "                                                {handle},\n",
    "                                                CUSPARSE_OPERATION_NON_TRANSPOSE,\n",
    "                                                CUSPARSE_OPERATION_NON_TRANSPOSE,\n",
    "                                                &alpha, matB, matC, &beta, matA, {compute},\n",
    "                                                CUSPARSE_SDDMM_ALG_DEFAULT, &bufferSize) );\n",
    "            cudaMalloc(&dBuffer, bufferSize);\n",
    "\n",
    "            // execute SpMM\n",
    "            dace::sparse::CheckCusparseError( cusparseSDDMM(\n",
    "                                                {handle},\n",
    "                                                CUSPARSE_OPERATION_NON_TRANSPOSE,\n",
    "                                                CUSPARSE_OPERATION_NON_TRANSPOSE,\n",
    "                                                &alpha, matB, matC, &beta, matA, {compute},\n",
    "                                                CUSPARSE_SDDMM_ALG_DEFAULT, dBuffer) );\n",
    "\n",
    "            // destroy matrix/vector descriptors\n",
    "            dace::sparse::CheckCusparseError( cusparseDestroySpMat(matA) );\n",
    "            dace::sparse::CheckCusparseError( cusparseDestroyDnMat(matB) );\n",
    "            dace::sparse::CheckCusparseError( cusparseDestroyDnMat(matC) );\n",
    "            cudaFree(dBuffer);\n",
    "        \"\"\"\n",
    "\n",
    "        code = (call_prefix + call + call_suffix)\n",
    "        tasklet = dace.sdfg.nodes.Tasklet(\n",
    "            node.name,\n",
    "            node.in_connectors,\n",
    "            node.out_connectors,\n",
    "            code,\n",
    "            language=dace.dtypes.Language.CPP,\n",
    "        )\n",
    "\n",
    "        # If buffers are not on the GPU, copy them\n",
    "        if needs_copy:\n",
    "            nsdfg = dace.SDFG('nested_gemm')\n",
    "            copies = [('_a_rows', a_indptr_arr), ('_a_cols', a_indices_arr), ('_a_vals', a_data_arr), ('_b', b_arr),\n",
    "                      ('_c', c_arr), ('_d_rows', d_indptr_arr), ('_d_cols', d_indices_arr), ('_d_vals', d_data_arr),]\n",
    "            for name, desc in copies:\n",
    "                if isinstance(desc, dace.data.View):\n",
    "                    dcopy = desc.as_array()\n",
    "                else:\n",
    "                    dcopy = copy.deepcopy(desc)\n",
    "                dcopy.lifetime = dace.AllocationLifetime.Scope\n",
    "                dcopy_gpu = copy.deepcopy(dcopy)\n",
    "                dcopy.transient = False\n",
    "                nsdfg.add_datadesc(name, dcopy)\n",
    "                dcopy_gpu.transient = True\n",
    "                dcopy_gpu.storage = dace.StorageType.GPU_Global\n",
    "                nsdfg.add_datadesc(name + '_gpu', dcopy_gpu)\n",
    "            nstate = nsdfg.add_state()\n",
    "            har, hac, had, hb, hc, hdr, hdc, hdd = (nstate.add_access(n) for n in (\n",
    "                '_a_indptr', '_a_indices', '_a_data', '_b', '_c', '_d_indptr', '_d_indices', '_d_data'))\n",
    "            gar, gac, gad, gb, gc, gdr, gdc, gdd = (nstate.add_access(n) for n in (\n",
    "                '_a_indptr_gpu', '_a_indices_gpu', '_a_data_gpu', '_b_gpu', '_c_gpu',\n",
    "                '_d_indptr_gpu', '_d_indices_gpu', '_d_data_gpu'))\n",
    "\n",
    "            # Reset code and connectors\n",
    "            tasklet.in_connectors = {\"_conn\" + k: None for k in tasklet.in_connectors}\n",
    "            tasklet.out_connectors = {\"_conn\" + k: None for k in tasklet.out_connectors}\n",
    "\n",
    "            nstate.add_nedge(har, gar, dace.Memlet.from_array('_a_indptr', a_indptr_arr))\n",
    "            nstate.add_nedge(hac, gac, dace.Memlet.from_array('_a_indices', a_indices_arr))\n",
    "            nstate.add_nedge(had, gad, dace.Memlet.from_array('_a_data', a_data_arr))\n",
    "            nstate.add_nedge(hb, gb, dace.Memlet.from_array('_b', b_arr))\n",
    "            nstate.add_nedge(hc, gc, dace.Memlet.from_array('_c', c_arr))\n",
    "\n",
    "            nstate.add_edge(gar, None, tasklet, '_conn_a_indptr', dace.Memlet.from_array('_a_indptr_gpu', a_indptr_arr))\n",
    "            nstate.add_edge(gac, None, tasklet, '_conn_a_indices', dace.Memlet.from_array('_a_indices_gpu', a_indices_arr))\n",
    "            nstate.add_edge(gad, None, tasklet, '_conn_a_data', dace.Memlet.from_array('_a_data_gpu', a_data_arr))\n",
    "            nstate.add_edge(gb, None, tasklet, '_conn_b', dace.Memlet.from_array('_b_gpu', b_arr))\n",
    "            nstate.add_edge(gc, None, tasklet, '_conn_c', dace.Memlet.from_array('_c_gpu', c_arr))\n",
    "            nstate.add_edge(tasklet, '_conn_d_indptr', gdr, None, dace.Memlet.from_array('_d_indptr_gpu', d_indptr_arr))\n",
    "            nstate.add_edge(tasklet, '_conn_d_indices', gdc, None, dace.Memlet.from_array('_d_indices_gpu', d_indices_arr))\n",
    "            nstate.add_edge(tasklet, '_conn_d_data', gdd, None, dace.Memlet.from_array('_d_data_gpu', d_data_arr))\n",
    "\n",
    "            nstate.add_nedge(gdr, hdr, dace.Memlet.from_array('_d_indptr', d_indptr_arr))\n",
    "            nstate.add_nedge(gdc, hdc, dace.Memlet.from_array('_d_indices', d_indices_arr))\n",
    "            nstate.add_nedge(gdd, hdd, dace.Memlet.from_array('_d_data', d_data_arr))\n",
    "\n",
    "            return nsdfg\n",
    "        # End of copy to GPU\n",
    "\n",
    "        return tasklet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We register this expansion with the `LibraryNode`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@library.node\n",
    "class MySDDMM(nodes.LibraryNode):\n",
    "\n",
    "    implementations: Dict[str, ExpandTransformation] = {'pure': MySDDMMPureExpansion, 'cuSPARSE': MySDDMMCuSPARSEExpansion}\n",
    "    default_implementation: str = 'pure'\n",
    "\n",
    "    def __init__(self, name, location=None):\n",
    "        super().__init__(name,\n",
    "                         location=location,\n",
    "                         inputs={'_a_data', '_a_indices', '_a_indptr', '_b', '_c'},\n",
    "                         outputs={'_d_data', '_d_indices', '_d_indptr'})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we auto-optimize the program and run it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied 1 GPUTransformSDFG.\n",
      "Automatically expanded library node \"_Transpose_\" with implementation \"cuBLAS\".\n",
      "Automatically expanded library node \"sddmm\" with implementation \"cuSPARSE\".\n",
      "Automatically expanded library node \"csrmm\" with implementation \"cuSPARSE\".\n",
      "Automatically expanded library node \"_MatMult_gemm\" with implementation \"cuBLAS\".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alziogas/Projects/dace/dace/sdfg/sdfg.py:2246: UserWarning: SDFG \"va_inference_layer\" is already loaded by another object, recompiling under a different name.\n",
      "  warnings.warn('SDFG \"%s\" is already loaded by another object, '\n",
      "/home/alziogas/Projects/dace/dace/codegen/targets/cuda.py:1753: UserWarning: Thread-block maps not found in kernel, assuming block size of (32,1,1)\n",
      "  warnings.warn('Thread-block maps not found in kernel, assuming block size of (%s)' %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Configuring done\n",
      "-- Generating done\n",
      "-- Build files have been written to: /home/alziogas/Projects/dace/tutorials/.dacecache/va_inference_layer/build\n",
      "\n",
      "[ 20%] Building NVCC (Device) object CMakeFiles/cuda_compile_1.dir/__/__/tutorials/.dacecache/va_inference_layer/src/cuda/cuda_compile_1_generated_va_inference_layer_0_cuda.cu.o\n",
      "/home/alziogas/Projects/dace/dace/codegen/../runtime/include/dace/../../../external/moodycamel/concurrentqueue.h(3599): warning #68-D: integer conversion resulted in a change of sign\n",
      "/home/alziogas/Projects/dace/dace/codegen/../runtime/include/dace/../../../external/moodycamel/concurrentqueue.h(3607): warning #68-D: integer conversion resulted in a change of sign\n",
      "\n",
      "[ 40%] Building CXX object CMakeFiles/va_inference_layer_0.dir/home/alziogas/Projects/dace/tutorials/.dacecache/va_inference_layer/src/cpu/va_inference_layer_0.cpp.o\n",
      "In file included from /home/alziogas/Projects/dace/dace/codegen/../runtime/include/dace/dace.h:14,\n",
      "                 from /home/alziogas/Projects/dace/tutorials/.dacecache/va_inference_layer/src/cpu/va_inference_layer_0.cpp:2:\n",
      "/home/alziogas/Projects/dace/dace/codegen/../runtime/include/dace/types.h: In constructor 'dace::half::half(float)':\n",
      "/home/alziogas/Projects/dace/dace/codegen/../runtime/include/dace/types.h:92:28: warning: dereferencing type-punned pointer will break strict-aliasing rules [-Wstrict-aliasing]\n",
      "             uint32_t x = *((uint32_t*)&f);\n",
      "                           ~^~~~~~~~~~~~~~\n",
      "[ 60%] Linking CXX shared library libva_inference_layer_0.so\n",
      "[ 60%] Built target va_inference_layer_0\n",
      "[100%] Built target dacestub_va_inference_layer_0\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9.3466355e-08"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dace.transformation.auto.auto_optimize import auto_optimize\n",
    "\n",
    "sdfg = va_inference_layer.to_sdfg()\n",
    "auto_optimize(sdfg, dace.DeviceType.GPU)\n",
    "func = sdfg.compile()\n",
    "func(A_data=A.data.copy(), A_indices=A.indices.copy(), A_indptr=A.indptr.copy(), H=H, W=W, H_prime=val, N=1000, K0=128, K1=128, NNZ=A.nnz)\n",
    "\n",
    "np.allclose(ref, val)\n",
    "np.linalg.norm(ref - val) / np.linalg.norm(ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311-dace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f4365af6226d83ec02cf1620d431f52c426cf97622e40406a6477f8a55cb5e80"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
